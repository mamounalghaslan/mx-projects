{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b77c6940-62c4-4c29-a2b5-7907260c33ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/yolov8\n",
      "/notebooks/yolov8\n"
     ]
    }
   ],
   "source": [
    "%cd yolov8\n",
    "!pwd\n",
    "\n",
    "# Dataset location\n",
    "DATASET_LOCATION = '/notebooks/datasets/yolov8-b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2965c846-d8d7-4920-932e-fb821c711479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.223 🚀 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro P5000, 16273MiB)\n",
      "Setup complete ✅ (8 CPUs, 29.4 GB RAM, 93.7/244.2 GB disk)\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "!pip install ultralytics\n",
    "\n",
    "# Import dependencies\n",
    "from IPython import display\n",
    "\n",
    "# Clear previous output\n",
    "display.clear_output()\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcd874c-742c-4499-928e-6b08e1fdb373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.222 🚀 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro P6000, 24443MiB)\n",
      "WARNING ⚠️ Upgrade to torch>=2.0.0 for deterministic training.\n",
      "\u001B[34m\u001B[1mengine/trainer: \u001B[0mtask=detect, mode=train, model=yolov8s.pt, data=/notebooks/datasets/yolov8-b/data.yaml, epochs=200, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train6, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train6\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2117209  ultralytics.nn.modules.head.Detect           [3, [128, 256, 512]]          \n",
      "Model summary: 225 layers, 11136761 parameters, 11136745 gradients, 28.7 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/detect/train6', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mchecks passed ✅\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning /notebooks/datasets/yolov8-b/train/labels.cache... 810 images, 0\u001B[0m\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /notebooks/datasets/yolov8-b/valid/labels.cache... 30 images, 0 ba\u001B[0m\n",
      "Plotting labels to runs/detect/train6/labels.jpg... \n",
      "\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001B[1mruns/detect/train6\u001B[0m\n",
      "Starting training for 200 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      1/200      9.28G       1.59      1.266      1.294       1725        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         30       4525      0.655      0.333      0.331      0.227\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      2/200      8.78G     0.9674     0.5379      0.963       1874        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         30       4525      0.952      0.333      0.454      0.326\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      3/200      11.2G     0.9312     0.5122     0.9418       1747        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         30       4525      0.885      0.542      0.579      0.396\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      4/200      9.04G     0.8809      0.476     0.9178       2818        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         30       4525      0.883      0.582       0.62       0.45\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      5/200        13G     0.8438     0.4498     0.9028       2523        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         30       4525      0.913      0.604      0.651      0.466\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      6/200      12.6G     0.8292     0.4375     0.8961       1895        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         30       4525      0.996      0.601      0.714      0.473\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      7/200      9.99G     0.8102     0.4239     0.8907       1686        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         30       4525       0.99      0.625      0.753      0.529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      8/200      8.71G     0.7914      0.408     0.8869       2582        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         30       4525      0.681      0.674      0.713      0.526\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      9/200      10.5G     0.7803     0.4013     0.8837       2098        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         30       4525      0.806      0.712       0.77      0.573\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     10/200      9.76G     0.7542      0.386     0.8788       2129        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         30       4525      0.861      0.822      0.831      0.606\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     11/200      9.46G     0.7375     0.3829     0.8744       2396        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         30       4525      0.857       0.89      0.855      0.605\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     12/200      10.5G     0.7476     0.3817      0.874       2769        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         30       4525      0.906      0.823      0.862      0.605\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     13/200      10.7G     0.7554     0.3812     0.8735       2393        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         30       4525      0.997      0.748      0.832       0.58\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     14/200        11G     0.7305     0.3729     0.8674       2103        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         30       4525      0.867      0.841      0.911      0.622\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     15/200      9.84G     0.7359     0.3729     0.8705       1817        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         30       4525      0.906       0.86        0.9      0.627\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     16/200      7.93G     0.7157     0.3685     0.8701       1338        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         30       4525       0.91      0.912       0.92      0.659\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     17/200      9.93G      0.727     0.3697     0.8683       2427        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         30       4525      0.906      0.888      0.929      0.622\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     18/200        10G     0.7117     0.3554     0.8654       1905        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         30       4525       0.93      0.845      0.937       0.65\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     19/200      9.85G     0.7047     0.3571     0.8649       1777        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         30       4525       0.96       0.89      0.936      0.621\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     20/200      12.3G      0.696     0.3496     0.8592       1858        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         30       4525      0.852      0.876      0.895      0.631\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     21/200      9.64G     0.6854     0.3435     0.8585       2559        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         30       4525      0.924      0.769      0.892      0.612\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     22/200      15.3G     0.6843     0.3435     0.8599       2079        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         30       4525      0.828      0.911      0.909       0.64\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     23/200      9.75G     0.6687     0.3428     0.8592       2022        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         30       4525      0.781      0.875      0.874      0.614\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     24/200       9.7G     0.6765     0.3477      0.859       1430        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         30       4525      0.909      0.888      0.901      0.623\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     25/200        11G     0.6559     0.3398     0.8551       2409        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         30       4525      0.905      0.913      0.932      0.651\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     26/200      8.15G     0.6708     0.3367      0.856       1778        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         30       4525      0.978       0.82      0.945      0.652\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     27/200      12.8G     0.6453     0.3311      0.853       2130        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         30       4525      0.934      0.935      0.962      0.643\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     28/200      9.78G     0.6295     0.3227     0.8512       1723        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         30       4525      0.959       0.89      0.958      0.669\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     29/200      9.81G     0.6349      0.333      0.853       2015        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         30       4525      0.938      0.864      0.934       0.66\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     30/200      11.1G     0.6224     0.3247     0.8489       2068        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         30       4525      0.848      0.837      0.879      0.624\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     31/200      9.63G      0.652     0.3344     0.8533       1906        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         30       4525      0.982      0.861      0.911      0.663\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     32/200      5.94G     0.6173     0.3178     0.8507       1934        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         30       4525      0.918      0.978      0.962      0.625\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     33/200      9.32G     0.6084      0.317     0.8458       1822        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         30       4525      0.919      0.892      0.929      0.652\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     34/200      10.7G      0.611     0.3145     0.8441       2130        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         30       4525      0.994      0.888       0.94      0.664\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     35/200      8.45G     0.5854      0.304     0.8409       2213        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         30       4525       0.99      0.846      0.954      0.688\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     36/200      10.9G     0.5803     0.3022     0.8411       1454        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         30       4525      0.896      0.971      0.978       0.68\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     37/200      8.84G     0.5736      0.305     0.8396       2728        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         30       4525      0.981      0.909      0.976      0.691\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     38/200      11.7G      0.568     0.3012     0.8397       2311        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         30       4525      0.948      0.903      0.954      0.684\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     39/200      11.6G     0.5693     0.3044     0.8376       2609        640:  "
     ]
    }
   ],
   "source": [
    "# Train model with image size 640x640, 200 epochs, using yolov8s.pt as a starting point \n",
    "\n",
    "!yolo task=detect mode=train model=yolov8s.pt data={DATASET_LOCATION}/data.yaml epochs=200 imgsz=640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "608c930f-af3b-4d2a-aa39-0cc0db50f5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.222 🚀 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro P5000, 16273MiB)\n",
      "Model summary (fused): 168 layers, 11126745 parameters, 0 gradients, 28.4 GFLOPs\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
      "100%|████████████████████████████████████████| 755k/755k [00:00<00:00, 97.3MB/s]\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /notebooks/datasets/yolov8-b/test/labels.cache... 30 images, 0 bac\u001B[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         30       4523      0.987      0.909      0.957      0.767\n",
      "                   MIS         30         15          1      0.727      0.882      0.648\n",
      "                   OOS         30         15      0.962          1      0.995       0.78\n",
      "               Product         30       4493      0.998          1      0.995      0.873\n",
      "Speed: 2.7ms preprocess, 7.6ms inference, 0.0ms loss, 39.5ms postprocess per image\n",
      "Saving runs/detect/val3/predictions.json...\n",
      "Results saved to \u001B[1mruns/detect/val3\u001B[0m\n",
      "💡 Learn more at https://docs.ultralytics.com/modes/val\n"
     ]
    }
   ],
   "source": [
    "# validate model using the best weights from the training\n",
    "# Note that validation always reads the data.yaml file from the train folder, and refers to the \"val\" path. So for testing, the path of testing images is placed in the \"val\" path of the train folder.\n",
    "\n",
    "!yolo task=detect mode=val model=/notebooks/yolov8/runs/detect/train6/weights/best.pt data={DATASET_LOCATION}/data.yaml save_json=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3ec05b6-b065-4728-90b6-792946356ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ 'format' is missing. Using default 'format=torchscript'.\n",
      "Ultralytics YOLOv8.0.222 🚀 Python-3.9.16 torch-1.12.1+cu116 CPU (Intel Xeon E5-2623 v4 2.60GHz)\n",
      "Model summary (fused): 168 layers, 11126745 parameters, 0 gradients, 28.4 GFLOPs\n",
      "\n",
      "\u001B[34m\u001B[1mPyTorch:\u001B[0m starting from '/notebooks/yolov8/runs/detect/train6/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 7, 8400) (21.5 MB)\n",
      "\n",
      "\u001B[34m\u001B[1mTorchScript:\u001B[0m starting export with torch 1.12.1+cu116...\n",
      "\u001B[34m\u001B[1mTorchScript:\u001B[0m export success ✅ 3.6s, saved as '/notebooks/yolov8/runs/detect/train6/weights/best.torchscript' (42.8 MB)\n",
      "\n",
      "Export complete (5.9s)\n",
      "Results saved to \u001B[1m/notebooks/yolov8/runs/detect/train6/weights\u001B[0m\n",
      "Predict:         yolo predict task=detect model=/notebooks/yolov8/runs/detect/train6/weights/best.torchscript imgsz=640  \n",
      "Validate:        yolo val task=detect model=/notebooks/yolov8/runs/detect/train6/weights/best.torchscript imgsz=640 data=/notebooks/datasets/yolov8-b/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "💡 Learn more at https://docs.ultralytics.com/modes/export\n"
     ]
    }
   ],
   "source": [
    "# Exporting the model\n",
    "\n",
    "!yolo export model=/notebooks/yolov8/runs/detect/train6/weights/best.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59bfd274-bef7-462d-b3d1-9640bc060132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.223 🚀 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro P5000, 16273MiB)\n",
      "Model summary (fused): 168 layers, 11126745 parameters, 0 gradients, 28.4 GFLOPs\n",
      "\n",
      "image 1/30 /notebooks/datasets/yolov8-b/test/images/20231030_073112_jpg.rf.889b4bf54054a064d71ec4b7894c24aa.jpg: 640x640 1 OOS, 10.7ms\n",
      "image 2/30 /notebooks/datasets/yolov8-b/test/images/20231030_073955_jpg.rf.9f5663e2dfac0a391a9bb77d3f5f67db.jpg: 640x640 1 OOS, 11.1ms\n",
      "image 3/30 /notebooks/datasets/yolov8-b/test/images/20231030_074911_jpg.rf.b71bfb1baea89ea622709fd5d30f6524.jpg: 640x640 1 OOS, 10.2ms\n",
      "image 4/30 /notebooks/datasets/yolov8-b/test/images/20231030_080054_jpg.rf.30032e644634b909c5d2c5675723ba1b.jpg: 640x640 1 OOS, 9.3ms\n",
      "image 5/30 /notebooks/datasets/yolov8-b/test/images/20231030_081111_jpg.rf.3b519d4cc768e790c1410367d09bcab1.jpg: 640x640 1 OOS, 9.7ms\n",
      "image 6/30 /notebooks/datasets/yolov8-b/test/images/20231030_081746_jpg.rf.5ab402e27192e184510ca9fa68bf6c8b.jpg: 640x640 1 OOS, 9.6ms\n",
      "image 7/30 /notebooks/datasets/yolov8-b/test/images/20231030_082654_jpg.rf.187b0b85bb05ab215a7147e29d0f3765.jpg: 640x640 1 OOS, 11.3ms\n",
      "image 8/30 /notebooks/datasets/yolov8-b/test/images/20231030_083507_jpg.rf.f6d0fb7eb053e3d31b98a71d4cd83c1d.jpg: 640x640 1 OOS, 10.0ms\n",
      "image 9/30 /notebooks/datasets/yolov8-b/test/images/20231030_084056_jpg.rf.0ae79f751fec2254332457b20dc633f3.jpg: 640x640 1 OOS, 9.8ms\n",
      "image 10/30 /notebooks/datasets/yolov8-b/test/images/20231030_084746_jpg.rf.1cfda7577e27a51772574026fe593b8d.jpg: 640x640 1 OOS, 11.3ms\n",
      "image 11/30 /notebooks/datasets/yolov8-b/test/images/20231030_085403_jpg.rf.bba35d2ca9c81e37d3235533ecf25467.jpg: 640x640 1 OOS, 9.8ms\n",
      "image 12/30 /notebooks/datasets/yolov8-b/test/images/20231030_090538_jpg.rf.81792f318a9ddf856302a17d79fc4db8.jpg: 640x640 1 OOS, 9.4ms\n",
      "image 13/30 /notebooks/datasets/yolov8-b/test/images/20231030_090807_jpg.rf.31c32f52feefa82033f263dc91af4036.jpg: 640x640 1 OOS, 9.8ms\n",
      "image 14/30 /notebooks/datasets/yolov8-b/test/images/20231030_090844_jpg.rf.cd28216da01eacc337cd50e193701724.jpg: 640x640 1 OOS, 9.6ms\n",
      "image 15/30 /notebooks/datasets/yolov8-b/test/images/20231030_090907_jpg.rf.5aeb244845a95fb3323775760d9ba537.jpg: 640x640 1 OOS, 10.0ms\n",
      "image 16/30 /notebooks/datasets/yolov8-b/test/images/20231030_092926_jpg.rf.a8e493d02b9204e84b2ec9d09b9b8752.jpg: 640x640 1 MIS, 9.5ms\n",
      "image 17/30 /notebooks/datasets/yolov8-b/test/images/20231030_092943_jpg.rf.073ea1157172ff95e9c6eadfd538e0ef.jpg: 640x640 (no detections), 9.6ms\n",
      "image 18/30 /notebooks/datasets/yolov8-b/test/images/20231030_093009_jpg.rf.c129150b73ea84dce6f9063807b4a1c1.jpg: 640x640 1 MIS, 9.6ms\n",
      "image 19/30 /notebooks/datasets/yolov8-b/test/images/20231030_093023_jpg.rf.0a99083fc302a5f0b24283668a93d097.jpg: 640x640 1 MIS, 10.1ms\n",
      "image 20/30 /notebooks/datasets/yolov8-b/test/images/20231030_093030_jpg.rf.6f856e5af15ca2652ee9befef5104c41.jpg: 640x640 1 MIS, 9.6ms\n",
      "image 21/30 /notebooks/datasets/yolov8-b/test/images/20231030_093110_jpg.rf.c7c65922adda5bb6ea087de8eeb8a1e5.jpg: 640x640 1 MIS, 10.4ms\n",
      "image 22/30 /notebooks/datasets/yolov8-b/test/images/20231030_093127_jpg.rf.f5006163132f68348fd963a25943fe6b.jpg: 640x640 (no detections), 10.3ms\n",
      "image 23/30 /notebooks/datasets/yolov8-b/test/images/20231030_093135_jpg.rf.11eaf944a73f7f8a1364cf79456c287b.jpg: 640x640 (no detections), 10.3ms\n",
      "image 24/30 /notebooks/datasets/yolov8-b/test/images/20231030_093209_jpg.rf.30bcd928218ce6f35bf59b371e4d1a2c.jpg: 640x640 (no detections), 10.3ms\n",
      "image 25/30 /notebooks/datasets/yolov8-b/test/images/20231030_093303_jpg.rf.3a1cb23ff615c3f2cbc2f7e7566201fa.jpg: 640x640 1 MIS, 10.3ms\n",
      "image 26/30 /notebooks/datasets/yolov8-b/test/images/20231030_093325_jpg.rf.09c5d36b29ead2fa582a3980f423f69b.jpg: 640x640 (no detections), 11.3ms\n",
      "image 27/30 /notebooks/datasets/yolov8-b/test/images/20231030_093356_jpg.rf.f44092bef006e95d405778ee0164ef8b.jpg: 640x640 1 MIS, 9.6ms\n",
      "image 28/30 /notebooks/datasets/yolov8-b/test/images/20231030_093420_jpg.rf.9b5dbfe91244583825970fc53affd726.jpg: 640x640 1 MIS, 9.9ms\n",
      "image 29/30 /notebooks/datasets/yolov8-b/test/images/20231030_093646_jpg.rf.66036b80865c71a308038512409232cf.jpg: 640x640 1 MIS, 9.7ms\n",
      "image 30/30 /notebooks/datasets/yolov8-b/test/images/20231030_093836_jpg.rf.b386e7b7194ba68a7ffb2b800abc7430.jpg: 640x640 1 MIS, 9.5ms\n",
      "Speed: 1.5ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001B[1mruns/detect/predict5\u001B[0m\n",
      "💡 Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    }
   ],
   "source": [
    "# Making predictions on the test set\n",
    "\n",
    "!yolo predict model=/notebooks/yolov8/runs/detect/train6/weights/best.pt source={DATASET_LOCATION}/test/images classes=[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02df5069-8531-42af-839f-d7b04445bc23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
